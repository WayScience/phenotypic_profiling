{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import itertools\n",
    "from joblib import load\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../utils\")\n",
    "from split_utils import get_features_data\n",
    "from train_utils import get_dataset\n",
    "from evaluate_utils import model_confusion_matrix, get_SCM_model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load features data from indexes and features dataframe\n",
    "data_split_path = pathlib.Path(\"../1.split_data/indexes/data_split_indexes.tsv\")\n",
    "data_split_indexes = pd.read_csv(data_split_path, sep=\"\\t\", index_col=0)\n",
    "features_dataframe_path = pathlib.Path(\"../0.download_data/data/labeled_data.csv.gz\")\n",
    "features_dataframe = get_features_data(features_dataframe_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Each Model on Each Dataset (multi class models)\n",
    "\n",
    "#### Note: `cm` stands for confusion matrix in variable names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory to load the models from\n",
    "models_dir = pathlib.Path(\"../2.train_model/models/multi_class_models/\")\n",
    "\n",
    "# use a list to keep track of scores in tidy long format for each model and dataset combination\n",
    "compiled_cm_data = []\n",
    "\n",
    "# iterate through each model (final model, shuffled baseline model, etc)\n",
    "# sorted so final models are shown before shuffled_baseline\n",
    "for model_path in sorted(models_dir.iterdir()):\n",
    "    model = load(model_path)\n",
    "    # determine model/feature type from model file name\n",
    "    model_type = model_path.name.split(\"__\")[0]\n",
    "    feature_type = model_path.name.split(\"__\")[1].replace(\".joblib\", \"\")\n",
    "\n",
    "    # iterate through label datasets (labels correspond to train, test, etc)\n",
    "    # with nested for loops, we test each model on each dataset(corresponding to a label)\n",
    "    for label in data_split_indexes[\"label\"].unique():\n",
    "        print(\n",
    "            f\"Evaluating model: {model_type} \\nTrained with features: {feature_type} \\nEvaluating with dataset: {label}\"\n",
    "        )\n",
    "\n",
    "        # load dataset (train, test, etc)\n",
    "        data = get_dataset(features_dataframe, data_split_indexes, label)\n",
    "        # set figure size before creating confusion matrix\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        # plot confusion matrix for chosen model evaluated on chosen dataset\n",
    "        cm_data, ax = model_confusion_matrix(model, data, feature_type)\n",
    "        ax.set_title(\"Phenotypic Class Predicitions\")\n",
    "        ax.set_xlabel(\"Predicted Label\")\n",
    "        ax.set_ylabel(\"True Label\")\n",
    "        plt.show()\n",
    "\n",
    "        # add confusion matrix data to compiled dataframe in tidy format\n",
    "        # use stack to restructure dataframe into tidy long format\n",
    "        cm_data = cm_data.stack()\n",
    "        # reset index must be used to make indexes at level 0 and 1 into individual columns\n",
    "        # these columns correspond to true label and predicted label, and are set as indexes after using stack()\n",
    "        cm_data = pd.DataFrame(cm_data).reset_index(level=[0, 1])\n",
    "        cm_data.columns = [\"True_Label\", \"Predicted_Label\", \"Count\"]\n",
    "        # add data split column to indicate which dataset scores are from (train, test, etc)\n",
    "        cm_data[\"data_split\"] = label\n",
    "        # add shuffled column to indicate if the model has been trained with shuffled data (random baseline) or not\n",
    "        cm_data[\"shuffled\"] = \"shuffled\" in model_type\n",
    "        # add feature type column to indicate which features model has been trained on/is using\n",
    "        cm_data[\"feature_type\"] = feature_type\n",
    "\n",
    "        # add this score data to the tidy scores compiling list\n",
    "        compiled_cm_data.append(cm_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save PR curve data from each evaluation (multi class models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile list of tidy data into one dataframe\n",
    "compiled_cm_data = pd.concat(compiled_cm_data).reset_index(drop=True)\n",
    "\n",
    "# specify results directory\n",
    "cm_data_dir = pathlib.Path(\"evaluations/confusion_matrices/\")\n",
    "cm_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# define save path\n",
    "compiled_cm_data_save_path = pathlib.Path(f\"{cm_data_dir}/compiled_cm_data.tsv\")\n",
    "\n",
    "# save data as tsv\n",
    "compiled_cm_data.to_csv(compiled_cm_data_save_path, sep=\"\\t\")\n",
    "\n",
    "# preview tidy data\n",
    "compiled_cm_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Each Model on Each Dataset (single class models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# directory to load the models from\n",
    "models_dir = pathlib.Path(\"../2.train_model/models/single_class_models/\")\n",
    "\n",
    "# use a list to keep track of scores in tidy long format for each model and dataset combination\n",
    "compiled_cm_data = []\n",
    "\n",
    "# define combinations to test over\n",
    "model_types = [\"final\", \"shuffled_baseline\"]\n",
    "feature_types = [\"CP\", \"DP\", \"CP_and_DP\"]\n",
    "evaluation_types = [\"train\", \"test\"]\n",
    "phenotypic_classes = features_dataframe[\"Mitocheck_Phenotypic_Class\"].unique()\n",
    "\n",
    "# iterate through each combination of feature_types, evaluation_types, phenotypic_classes\n",
    "for model_type, feature_type, evaluation_type in itertools.product(\n",
    "    model_types, feature_types, evaluation_types\n",
    "):\n",
    "    # create a figure that has 3x5 subplots for 15 phenotypic classes\n",
    "    fig, axs = plt.subplots(3, 5)\n",
    "    fig.set_size_inches(30, 18)\n",
    "    # variables to keep track of figure subplot coordinates\n",
    "    ax_x = 0\n",
    "    ax_y = 0\n",
    "\n",
    "    for phenotypic_class in phenotypic_classes:\n",
    "        # load single class model for this combination of model type, feature type, and phenotypic class\n",
    "        single_class_model_path = pathlib.Path(\n",
    "            f\"{models_dir}/{phenotypic_class}_models/{model_type}__{feature_type}.joblib\"\n",
    "        )\n",
    "        single_class_model = load(single_class_model_path)\n",
    "\n",
    "        # load dataset (train, test, etc)\n",
    "        single_cell_data = get_dataset(\n",
    "            features_dataframe, data_split_indexes, evaluation_type\n",
    "        )\n",
    "        # rename negative labels and downsample negative lables if we are evaluating on training data\n",
    "        single_cell_data = get_SCM_model_data(\n",
    "            single_cell_data, phenotypic_class, evaluation_type\n",
    "        )\n",
    "\n",
    "        # make font small for phenotypic class labels\n",
    "        plt.rcParams.update({\"font.size\": 11})\n",
    "        # find confusion matrix for chosen model evaluated on chosen dataset\n",
    "        cm_data, _ = model_confusion_matrix(\n",
    "            single_class_model, single_cell_data, feature_type, ax=axs[ax_x, ax_y]\n",
    "        )\n",
    "\n",
    "        # add confusion matrix data to compiled dataframe in tidy format\n",
    "        # use stack to restructure dataframe into tidy long format\n",
    "        cm_data = cm_data.stack()\n",
    "        # reset index must be used to make indexes at level 0 and 1 into individual columns\n",
    "        # these columns correspond to true label and predicted label, and are set as indexes after using stack()\n",
    "        cm_data = pd.DataFrame(cm_data).reset_index(level=[0, 1])\n",
    "        cm_data.columns = [\"True_Label\", \"Predicted_Label\", \"Count\"]\n",
    "        # add data split column to indicate which dataset scores are from (train, test, etc)\n",
    "        cm_data[\"data_split\"] = evaluation_type\n",
    "        # add shuffled column to indicate if the model has been trained with shuffled data (random baseline) or not\n",
    "        cm_data[\"shuffled\"] = \"shuffled\" in model_type\n",
    "        # add feature type column to indicate which features model has been trained on/is using\n",
    "        cm_data[\"feature_type\"] = feature_type\n",
    "\n",
    "        # add this score data to the tidy scores compiling list\n",
    "        compiled_cm_data.append(cm_data)\n",
    "\n",
    "        # increase row coordinate counter (this marks which subplot to plot on in vertical direction)\n",
    "        ax_x += 1\n",
    "        # if row coordinate counter is at maximum (3 rows of subplots)\n",
    "        if ax_x == 3:\n",
    "            # set row coordinate counter to 0\n",
    "            ax_x = 0\n",
    "            # increase column coordinate counter (this marks which subplot to plot on in horizontal direction)\n",
    "            ax_y += 1\n",
    "\n",
    "    # add title and axes labels to figure\n",
    "    fig.suptitle(\n",
    "        f\"Single Class Model Confusion Matrices for Combination: {model_type}, {feature_type}, {evaluation_type}\"\n",
    "    )\n",
    "    fig.supxlabel(\"Predicted Label\")\n",
    "    fig.supylabel(\"True Label\")\n",
    "    plt.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save PR curve data from each evaluation (single class models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile list of tidy data into one dataframe\n",
    "compiled_cm_data = pd.concat(compiled_cm_data).reset_index(drop=True)\n",
    "\n",
    "# specify results directory\n",
    "cm_data_dir = pathlib.Path(\"evaluations/confusion_matrices/\")\n",
    "cm_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# define save path\n",
    "compiled_cm_data_save_path = pathlib.Path(f\"{cm_data_dir}/compiled_SCM_cm_data.tsv\")\n",
    "\n",
    "# save data as tsv\n",
    "compiled_cm_data.to_csv(compiled_cm_data_save_path, sep=\"\\t\")\n",
    "\n",
    "# preview tidy data\n",
    "compiled_cm_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('phenotypic_profiling')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9df586d1764dbc68785000a153dad1832127ac564b5e2e4c94e83fc43160b30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
