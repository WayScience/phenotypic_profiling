{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import warnings\n",
    "import sys\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import load\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    GridSearchCV,\n",
    ")\n",
    "from sklearn.utils import parallel_backend\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "sys.path.append(\"../utils\")\n",
    "from split_utils import get_features_data\n",
    "from train_utils import get_X_y_data\n",
    "from evaluate_utils import get_SCM_model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Load Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load labeled data\n",
    "labeled_data_dir_path = pathlib.Path(\"../0.download_data/data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See number of cells for LOIO evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 270 images to perform LOIO evaluation on per model.\n"
     ]
    }
   ],
   "source": [
    "# load labeled data\n",
    "labeled_data_path = pathlib.Path(f\"{labeled_data_dir_path}/labeled_data__ic.csv.gz\")\n",
    "labeled_data = get_features_data(labeled_data_path)\n",
    "\n",
    "# see number of images to evaluate on\n",
    "num_images = labeled_data[\"Metadata_DNA\"].unique().shape[0]\n",
    "print(f\"There are {num_images} images to perform LOIO evaluation on per model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get LOIO probabilities (multi class models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02]),\n",
       " 'l1_ratio': array([0. , 0.2, 0.4, 0.6, 0.8, 1. ])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify parameters to tune for\n",
    "parameters = {\"C\": np.logspace(-2, 2, 5), \"l1_ratio\": np.linspace(0, 1, 6)}\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing LOIO for model with types final, balanced, CP, ic\n",
      "Training on everything but: LT0010_27/LT0010_27_173_83.tif\n",
      "Evaluating: LT0010_27/LT0010_27_173_83.tif\n"
     ]
    }
   ],
   "source": [
    "# directory to load the models from\n",
    "models_dir = pathlib.Path(\"../2.train_model/models/multi_class_models\")\n",
    "\n",
    "# use a list to keep track of LOIO probabilities in tidy long format for each model combination\n",
    "compiled_LOIO_wide_data = []\n",
    "\n",
    "# iterate through each model (final model, shuffled baseline model, etc)\n",
    "# sorted so final models are shown before shuffled_baseline\n",
    "for model_path in sorted(models_dir.iterdir()):\n",
    "    model = load(model_path)\n",
    "    # determine model/feature type/balance/dataset type from model file name\n",
    "    model_components = model_path.name.split(\"__\")\n",
    "    model_type = model_components[0]\n",
    "    feature_type = model_components[1]\n",
    "    balance_type = model_components[2]\n",
    "    # version of dataset used to train model (ic, no_ic)\n",
    "    dataset_type = model_components[3].replace(\".joblib\", \"\")\n",
    "\n",
    "    print(\n",
    "        f\"Performing LOIO for model with types {model_type}, {balance_type}, {feature_type}, {dataset_type}\"\n",
    "    )\n",
    "    \n",
    "    # load labeled data\n",
    "    labeled_data_path = pathlib.Path(f\"{labeled_data_dir_path}/labeled_data__{dataset_type}.csv.gz\")\n",
    "    labeled_data = get_features_data(labeled_data_path)\n",
    "\n",
    "    # iterate through image paths\n",
    "    for image_path in labeled_data[\"Metadata_DNA\"].unique():\n",
    "        print(f\"Training on everything but: {image_path}\")\n",
    "        # get training and testing cells from image path\n",
    "        # every cell from the image path is for testing, the rest are for training\n",
    "        train_cells = labeled_data.loc[labeled_data[\"Metadata_DNA\"] != image_path]\n",
    "        test_cells = labeled_data.loc[labeled_data[\"Metadata_DNA\"] == image_path]\n",
    "\n",
    "        # get X, y from training and testing cells\n",
    "        X_train, y_train = get_X_y_data(train_cells, feature_type)\n",
    "        \n",
    "        # shuffle columns of X (features) dataframe independently to create shuffled baseline\n",
    "        if model_type == \"shuffled_baseline\":\n",
    "            for column in X_train.T:\n",
    "                np.random.shuffle(column)\n",
    "                \n",
    "        X_test, y_test = get_X_y_data(test_cells, feature_type)\n",
    "\n",
    "        # Setup grid search logic\n",
    "        straified_k_folds = StratifiedKFold(n_splits=10, shuffle=False)\n",
    "        \n",
    "        # create logistic regression model with following parameters\n",
    "        log_reg_model = LogisticRegression(\n",
    "            penalty=\"elasticnet\", solver=\"saga\", max_iter=100, n_jobs=-1, random_state=0\n",
    "        )\n",
    "\n",
    "        # create grid search with cross validation with hypertuning params\n",
    "        grid_search_cv = GridSearchCV(\n",
    "            log_reg_model,\n",
    "            parameters,\n",
    "            cv=straified_k_folds,\n",
    "            n_jobs=-1,\n",
    "            scoring=\"f1_weighted\",\n",
    "        )\n",
    "\n",
    "        # capture convergence warning from sklearn\n",
    "        # this warning does not affect the model but takes up lots of space in the output\n",
    "        # this warning must be caught with parallel_backend because the logistic regression model uses parallel_backend\n",
    "        # (n_jobs=-1 means use all processors)\n",
    "        with parallel_backend(\"multiprocessing\"):\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings(\n",
    "                    \"ignore\", category=ConvergenceWarning, module=\"sklearn\"\n",
    "                )\n",
    "\n",
    "                # fit a logisitc regression model on the training X, y\n",
    "                LOIO_model = grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "        # create metadata dataframe for test cells with model parameters\n",
    "        metadata_dataframe = pd.concat(\n",
    "            [\n",
    "                test_cells[\"Cell_UUID\"],\n",
    "                test_cells[\"Metadata_DNA\"],\n",
    "                test_cells[\"Mitocheck_Phenotypic_Class\"],\n",
    "            ],\n",
    "            axis=1,\n",
    "        ).reset_index(drop=True)\n",
    "        metadata_dataframe[\"Model_Feature_Type\"] = feature_type\n",
    "        metadata_dataframe[\"Model_C\"] = grid_search_cv.best_params_[\"C\"]\n",
    "        metadata_dataframe[\"Model_l1_ratio\"] = grid_search_cv.best_params_[\"l1_ratio\"]\n",
    "        metadata_dataframe[\"Model_type\"] = model_type\n",
    "\n",
    "        # predict probabilities for test cells and make these probabilities into a dataframe\n",
    "        print(f\"Evaluating: {image_path}\")\n",
    "        probas = LOIO_model.predict_proba(X_test)\n",
    "        probas_dataframe = pd.DataFrame(probas, columns=model.classes_)\n",
    "\n",
    "        # combine metadata and probabilities dataframes for test cells to create wide data\n",
    "        test_cells_wide_data = pd.concat([metadata_dataframe, probas_dataframe], axis=1)\n",
    "\n",
    "        # add tidy long data to compiled data\n",
    "        compiled_LOIO_wide_data.append(test_cells_wide_data)\n",
    "        \n",
    "        break\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format and save LOIO probabilities (multi class models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell_UUID</th>\n",
       "      <th>Metadata_DNA</th>\n",
       "      <th>Mitocheck_Phenotypic_Class</th>\n",
       "      <th>Model_Feature_Type</th>\n",
       "      <th>Model_C</th>\n",
       "      <th>Model_l1_ratio</th>\n",
       "      <th>Model_type</th>\n",
       "      <th>Model_Phenotypic_Class</th>\n",
       "      <th>Predicted_Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>009a4190-7583-4821-9a17-737f0485d252</td>\n",
       "      <td>LT0010_27/LT0010_27_173_83.tif</td>\n",
       "      <td>Elongated</td>\n",
       "      <td>CP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>final</td>\n",
       "      <td>ADCCM</td>\n",
       "      <td>0.000363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>009a4190-7583-4821-9a17-737f0485d252</td>\n",
       "      <td>LT0010_27/LT0010_27_173_83.tif</td>\n",
       "      <td>Elongated</td>\n",
       "      <td>CP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>final</td>\n",
       "      <td>Anaphase</td>\n",
       "      <td>0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>009a4190-7583-4821-9a17-737f0485d252</td>\n",
       "      <td>LT0010_27/LT0010_27_173_83.tif</td>\n",
       "      <td>Elongated</td>\n",
       "      <td>CP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>final</td>\n",
       "      <td>Apoptosis</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>009a4190-7583-4821-9a17-737f0485d252</td>\n",
       "      <td>LT0010_27/LT0010_27_173_83.tif</td>\n",
       "      <td>Elongated</td>\n",
       "      <td>CP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>final</td>\n",
       "      <td>Binuclear</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>009a4190-7583-4821-9a17-737f0485d252</td>\n",
       "      <td>LT0010_27/LT0010_27_173_83.tif</td>\n",
       "      <td>Elongated</td>\n",
       "      <td>CP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>final</td>\n",
       "      <td>Elongated</td>\n",
       "      <td>0.991004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>f74ce97f-5862-419b-a9a8-44ad53d332a2</td>\n",
       "      <td>LT0010_27/LT0010_27_173_83.tif</td>\n",
       "      <td>Elongated</td>\n",
       "      <td>CP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>final</td>\n",
       "      <td>MetaphaseAlignment</td>\n",
       "      <td>0.001396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>f74ce97f-5862-419b-a9a8-44ad53d332a2</td>\n",
       "      <td>LT0010_27/LT0010_27_173_83.tif</td>\n",
       "      <td>Elongated</td>\n",
       "      <td>CP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>final</td>\n",
       "      <td>OutOfFocus</td>\n",
       "      <td>0.054337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>f74ce97f-5862-419b-a9a8-44ad53d332a2</td>\n",
       "      <td>LT0010_27/LT0010_27_173_83.tif</td>\n",
       "      <td>Elongated</td>\n",
       "      <td>CP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>final</td>\n",
       "      <td>Polylobed</td>\n",
       "      <td>0.025900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>f74ce97f-5862-419b-a9a8-44ad53d332a2</td>\n",
       "      <td>LT0010_27/LT0010_27_173_83.tif</td>\n",
       "      <td>Elongated</td>\n",
       "      <td>CP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>final</td>\n",
       "      <td>Prometaphase</td>\n",
       "      <td>0.000412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>f74ce97f-5862-419b-a9a8-44ad53d332a2</td>\n",
       "      <td>LT0010_27/LT0010_27_173_83.tif</td>\n",
       "      <td>Elongated</td>\n",
       "      <td>CP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>final</td>\n",
       "      <td>SmallIrregular</td>\n",
       "      <td>0.000165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Cell_UUID                    Metadata_DNA  \\\n",
       "0    009a4190-7583-4821-9a17-737f0485d252  LT0010_27/LT0010_27_173_83.tif   \n",
       "1    009a4190-7583-4821-9a17-737f0485d252  LT0010_27/LT0010_27_173_83.tif   \n",
       "2    009a4190-7583-4821-9a17-737f0485d252  LT0010_27/LT0010_27_173_83.tif   \n",
       "3    009a4190-7583-4821-9a17-737f0485d252  LT0010_27/LT0010_27_173_83.tif   \n",
       "4    009a4190-7583-4821-9a17-737f0485d252  LT0010_27/LT0010_27_173_83.tif   \n",
       "..                                    ...                             ...   \n",
       "355  f74ce97f-5862-419b-a9a8-44ad53d332a2  LT0010_27/LT0010_27_173_83.tif   \n",
       "356  f74ce97f-5862-419b-a9a8-44ad53d332a2  LT0010_27/LT0010_27_173_83.tif   \n",
       "357  f74ce97f-5862-419b-a9a8-44ad53d332a2  LT0010_27/LT0010_27_173_83.tif   \n",
       "358  f74ce97f-5862-419b-a9a8-44ad53d332a2  LT0010_27/LT0010_27_173_83.tif   \n",
       "359  f74ce97f-5862-419b-a9a8-44ad53d332a2  LT0010_27/LT0010_27_173_83.tif   \n",
       "\n",
       "    Mitocheck_Phenotypic_Class Model_Feature_Type  Model_C  Model_l1_ratio  \\\n",
       "0                    Elongated                 CP      1.0             0.4   \n",
       "1                    Elongated                 CP      1.0             0.4   \n",
       "2                    Elongated                 CP      1.0             0.4   \n",
       "3                    Elongated                 CP      1.0             0.4   \n",
       "4                    Elongated                 CP      1.0             0.4   \n",
       "..                         ...                ...      ...             ...   \n",
       "355                  Elongated                 CP      1.0             0.4   \n",
       "356                  Elongated                 CP      1.0             0.4   \n",
       "357                  Elongated                 CP      1.0             0.4   \n",
       "358                  Elongated                 CP      1.0             0.4   \n",
       "359                  Elongated                 CP      1.0             0.4   \n",
       "\n",
       "    Model_type Model_Phenotypic_Class  Predicted_Probability  \n",
       "0        final                  ADCCM               0.000363  \n",
       "1        final               Anaphase               0.000045  \n",
       "2        final              Apoptosis               0.000022  \n",
       "3        final              Binuclear               0.000016  \n",
       "4        final              Elongated               0.991004  \n",
       "..         ...                    ...                    ...  \n",
       "355      final     MetaphaseAlignment               0.001396  \n",
       "356      final             OutOfFocus               0.054337  \n",
       "357      final              Polylobed               0.025900  \n",
       "358      final           Prometaphase               0.000412  \n",
       "359      final         SmallIrregular               0.000165  \n",
       "\n",
       "[360 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile list of wide data into one dataframe\n",
    "compiled_LOIO_wide_data = pd.concat(compiled_LOIO_wide_data).reset_index(drop=True)\n",
    "\n",
    "# convert wide data to tidy long data and sort by Cell_UUID, Model_Feature_Type, and Model_Phenotypic_Class for pretty formatting\n",
    "compiled_LOIO_tidy_long_data = (\n",
    "    pd.melt(\n",
    "        compiled_LOIO_wide_data,\n",
    "        id_vars=metadata_dataframe.columns,\n",
    "        value_vars=probas_dataframe.columns,\n",
    "        var_name=\"Model_Phenotypic_Class\",\n",
    "        value_name=\"Predicted_Probability\",\n",
    "    )\n",
    "    .sort_values([\"Model_Feature_Type\", \"Cell_UUID\", \"Model_Phenotypic_Class\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# specify results directory\n",
    "LOIO_probas_dir = pathlib.Path(\"evaluations/LOIO_probas/\")\n",
    "LOIO_probas_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# define save path\n",
    "compiled_LOIO_save_path = pathlib.Path(\n",
    "    f\"{LOIO_probas_dir}/compiled_LOIO_probabilites_withshuffled.tsv\"\n",
    ")\n",
    "\n",
    "# save data as tsv\n",
    "compiled_LOIO_tidy_long_data.to_csv(compiled_LOIO_save_path, sep=\"\\t\")\n",
    "\n",
    "# preview tidy long data\n",
    "compiled_LOIO_tidy_long_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get LOIO probabilities (single class models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory to load the models from\n",
    "models_dir = pathlib.Path(\"../2.train_model/models/single_class_models\")\n",
    "\n",
    "# use a list to keep track of LOIO probabilities in tidy long format for each model combination\n",
    "compiled_LOIO_wide_data = []\n",
    "\n",
    "# define combinations to test over\n",
    "model_types = [\n",
    "    \"final\"\n",
    "]  # only perform LOIO with hyper params from final models so skip shuffled_baseline models\n",
    "feature_types = [\"CP\", \"DP\", \"CP_and_DP\"]\n",
    "phenotypic_classes = labeled_data[\"Mitocheck_Phenotypic_Class\"].unique()\n",
    "\n",
    "# iterate through each combination of feature_types, evaluation_types, phenotypic_classes\n",
    "for model_type, feature_type, phenotypic_class in itertools.product(\n",
    "    model_types, feature_types, phenotypic_classes\n",
    "):\n",
    "    single_class_model_path = pathlib.Path(\n",
    "        f\"{models_dir}/{phenotypic_class}_models/{model_type}__{feature_type}.joblib\"\n",
    "    )\n",
    "\n",
    "    # load the model\n",
    "    model = load(single_class_model_path)\n",
    "\n",
    "    print(\n",
    "        f\"Performing LOIO on {phenotypic_class} model for feature type {feature_type} with parameters C: {model.C}, l1_ratio: {model.l1_ratio}\"\n",
    "    )\n",
    "\n",
    "    # iterate through image paths\n",
    "    for image_path in labeled_data[\"Metadata_DNA\"].unique():\n",
    "        # get training and testing cells from image path\n",
    "        # every cell from the image path is for testing, the rest are for training\n",
    "        train_cells = labeled_data.loc[labeled_data[\"Metadata_DNA\"] != image_path]\n",
    "        test_cells = labeled_data.loc[labeled_data[\"Metadata_DNA\"] == image_path]\n",
    "\n",
    "        # rename negative label and downsample over represented classes\n",
    "        train_cells = get_SCM_model_data(train_cells, phenotypic_class, \"train\")\n",
    "        test_cells = get_SCM_model_data(test_cells, phenotypic_class, \"test\")\n",
    "\n",
    "        # get X, y from training and testing cells\n",
    "        X_train, y_train = get_X_y_data(train_cells, feature_type)\n",
    "        X_test, y_test = get_X_y_data(test_cells, feature_type)\n",
    "\n",
    "        # capture convergence warning from sklearn\n",
    "        # this warning does not affect the model but takes up lots of space in the output\n",
    "        # this warning must be caught with parallel_backend because the logistic regression model uses parallel_backend\n",
    "        # (n_jobs=-1 means use all processors)\n",
    "        with parallel_backend(\"multiprocessing\"):\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings(\n",
    "                    \"ignore\", category=ConvergenceWarning, module=\"sklearn\"\n",
    "                )\n",
    "\n",
    "                # fit a logisitc regression model on the training X, y\n",
    "                LOIO_model = LogisticRegression(\n",
    "                    penalty=\"elasticnet\",\n",
    "                    solver=\"saga\",\n",
    "                    max_iter=100,\n",
    "                    n_jobs=-1,\n",
    "                    random_state=0,\n",
    "                    C=model.C,\n",
    "                    l1_ratio=model.l1_ratio,\n",
    "                ).fit(X_train, y_train)\n",
    "\n",
    "        # create metadata dataframe for test cells with model parameters\n",
    "        metadata_dataframe = pd.concat(\n",
    "            [\n",
    "                test_cells[\"Cell_UUID\"],\n",
    "                test_cells[\"Metadata_DNA\"],\n",
    "                test_cells[\"Mitocheck_Phenotypic_Class\"],\n",
    "            ],\n",
    "            axis=1,\n",
    "        ).reset_index(drop=True)\n",
    "        metadata_dataframe[\"Model_Feature_Type\"] = feature_type\n",
    "        metadata_dataframe[\"Model_C\"] = model.C\n",
    "        metadata_dataframe[\"Model_l1_ratio\"] = model.l1_ratio\n",
    "        metadata_dataframe[\"Model_Phenotypic_Class\"] = phenotypic_class\n",
    "\n",
    "        # predict probabilities for test cells and make these probabilities into a dataframe\n",
    "        probas = LOIO_model.predict_proba(X_test)\n",
    "        probas_dataframe = pd.DataFrame(probas, columns=model.classes_)\n",
    "        # make column names consistent for all single cell models (SCMs)\n",
    "        # positive label corresponds to that SCM's phenotypic class, negative is all other labels\n",
    "        probas_dataframe = probas_dataframe.rename(\n",
    "            columns={\n",
    "                phenotypic_class: \"Positive_Label\",\n",
    "                f\"Not {phenotypic_class}\": \"Negative_Label\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # combine metadata and probabilities dataframes for test cells to create wide data\n",
    "        test_cells_wide_data = pd.concat([metadata_dataframe, probas_dataframe], axis=1)\n",
    "\n",
    "        # add tidy long data to compiled data\n",
    "        compiled_LOIO_wide_data.append(test_cells_wide_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format and save LOIO probabilities (single class models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile list of wide data into one dataframe\n",
    "compiled_LOIO_wide_data = pd.concat(compiled_LOIO_wide_data).reset_index(drop=True)\n",
    "\n",
    "# convert wide data to tidy long data and sort by Cell_UUID, Model_Feature_Type, and Model_Phenotypic_Class for pretty formatting\n",
    "compiled_LOIO_tidy_long_data = (\n",
    "    pd.melt(\n",
    "        compiled_LOIO_wide_data,\n",
    "        id_vars=metadata_dataframe.columns,\n",
    "        value_vars=probas_dataframe.columns,\n",
    "        var_name=\"Predicted_Label\",\n",
    "        value_name=\"Predicted_Probability\",\n",
    "    )\n",
    "    .sort_values([\"Model_Feature_Type\", \"Cell_UUID\", \"Model_Phenotypic_Class\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# specify results directory\n",
    "LOIO_probas_dir = pathlib.Path(\"evaluations/LOIO_probas/\")\n",
    "LOIO_probas_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# define save path\n",
    "compiled_LOIO_save_path = pathlib.Path(\n",
    "    f\"{LOIO_probas_dir}/compiled_SCM_LOIO_probabilites.tsv\"\n",
    ")\n",
    "\n",
    "# save data as tsv\n",
    "compiled_LOIO_tidy_long_data.to_csv(compiled_LOIO_save_path, sep=\"\\t\")\n",
    "\n",
    "# preview tidy long data\n",
    "compiled_LOIO_tidy_long_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "f9df586d1764dbc68785000a153dad1832127ac564b5e2e4c94e83fc43160b30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
